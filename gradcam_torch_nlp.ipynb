{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradcam-torch-nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Two Options:\n",
        "1. pooled_output from self.bert is (batch_size, seq_len, embedding_size). Basically, pooled_output can be viewed as a representation learned. Since this vector has the same seq_len as the input, we can do an aggregation over the third axis so that each token will have a score for heatmap.\n",
        "2. directly back-prop to input_ids.\n",
        "\n",
        "Original Notebook: https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S#scrollTo=PGnlRWvkY-2c"
      ],
      "metadata": {
        "id": "XKccSzUBGqEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==2.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkz1EiA90AYp",
        "outputId": "14a8977d-67b6-44e7-eb2a-80d588284d44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==2.6.0\n",
            "  Downloading transformers-2.6.0-py3-none-any.whl (540 kB)\n",
            "\u001b[K     |████████████████████████████████| 540 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (3.6.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (1.21.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 32.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (4.63.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.16-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (2.23.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.16\n",
            "  Downloading botocore-1.24.16-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 31.4 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.16->boto3->transformers==2.6.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.16->boto3->transformers==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.6.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.16 botocore-1.24.16 jmespath-0.10.0 s3transfer-0.5.2 sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.6.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "wL66QZjRz9Rf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Path Vairables\n",
        "ROOT_DIR =  \"drive/MyDrive/11877-AMMML/\"\n",
        "DATASET_DIR = ROOT_DIR + \"dataset/random/nlp/\""
      ],
      "metadata": {
        "id": "cPGlvVF4t4BZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATASET_DIR + \"reviews.csv\")\n",
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)\n",
        "class_names = ['negative', 'neutral', 'positive']\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "YreelNrizvJi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "metadata": {
        "id": "_bSEyXSfE3j_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "  def __init__(self, texts, targets, tokenizer, max_len):\n",
        "    self.texts = texts\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.texts[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      # pad_to_max_length=True,\n",
        "      padding=\"max_length\",\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'text': text,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "ndNTmMUeFKE9"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(\n",
        "    texts=df.content.to_numpy()[:10],\n",
        "    targets=df.sentiment.to_numpy()[:10],\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=160\n",
        "  )\n",
        "\n",
        "dataloader = DataLoader(dataset=dataset, shuffle=True, batch_size=1)"
      ],
      "metadata": {
        "id": "MwufeVL_G8hN"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes, visualization=\"gradcam\"):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "\n",
        "    # raw or gradcam\n",
        "    self.visualization = visualization \n",
        "\n",
        "    # placeholder for the gradients\n",
        "    self.gradients = None\n",
        "\n",
        "\n",
        "  # hook for the gradients of the activations\n",
        "  def activations_hook(self, grad):\n",
        "    self.gradients = grad\n",
        "\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    self.raw_input = input_ids.clone().detach().cpu().numpy()\n",
        "    last_hidden_state, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    ) # We got a bunch of zero gradient problem because of the pooling operation, if we directly use last_hidden_state, this might be solved, but need retrain\n",
        "\n",
        "    # pooled_output = torch.mean(last_hidden_state, dim=1)\n",
        "    if self.visualization == \"gradcam\":\n",
        "      h = last_hidden_state.register_hook(self.activations_hook)\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)\n",
        "\n",
        "\n",
        "  # method for the gradient extraction\n",
        "  def get_activations_gradient(self):\n",
        "      return self.gradients\n",
        "\n",
        "  # method for the activation exctraction\n",
        "  def get_activations(self, input_ids, attention_mask):\n",
        "      if self.visualization == \"gradcam\":\n",
        "        last_hidden_state, pooled_output = self.bert(\n",
        "          input_ids=input_ids,\n",
        "          attention_mask=attention_mask\n",
        "        )\n",
        "        return last_hidden_state.detach().cpu().numpy()\n",
        "      elif self.visualization == \"raw\":\n",
        "        return self.raw_input\n",
        "      else:\n",
        "        return None\n",
        "\n",
        "  def get_raw_input(self):\n",
        "    return self.raw_input"
      ],
      "metadata": {
        "id": "oxetwmKhPZuc"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model.load_state_dict(torch.load(DATASET_DIR + 'sentiment.bin'))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "eMPczHRYPocS"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "data = next(iter(dataloader))\n",
        "\n",
        "text = data[\"text\"]\n",
        "input_ids = data[\"input_ids\"].to(device)\n",
        "attention_mask = data[\"attention_mask\"].to(device)\n",
        "targets = data[\"targets\"].to(device)\n",
        "\n",
        "outputs = model(\n",
        "  input_ids=input_ids,\n",
        "  attention_mask=attention_mask\n",
        ")\n",
        "\n",
        "probs = F.softmax(outputs, dim=1)\n",
        "_, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "pred_index = preds.detach().cpu().numpy()[0]\n",
        "\n",
        "print(\"Input text is\", text)\n",
        "print(\"Length of input_ids is\", len(input_ids[0]))\n",
        "print(\"Input tokens are\", tokenizer.convert_ids_to_tokens(input_ids[0]))\n",
        "print(\"Ground truth label is\", class_names[targets.detach().cpu().numpy()[0]])\n",
        "print(\"Prediction is\", class_names[pred_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZzSrrCMZS3_",
        "outputId": "b92acdf5-2fa9-4e40-ba47-ab5fe2bdc31e"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text is [\"I have been using forest since 2017 and had collected over 3000 coins. Unfortunately my phone got stolen and I had to buy a new one. Now when I reinstalled the app it's saying that I need to start collecting again and to log in I need a premium account which I have never had. How can I get my points back? Thank you.\"]\n",
            "Length of input_ids is 75\n",
            "Input tokens are ['[CLS]', 'I', 'have', 'been', 'using', 'forest', 'since', '2017', 'and', 'had', 'collected', 'over', '3000', 'coins', '.', 'Unfortunately', 'my', 'phone', 'got', 'stolen', 'and', 'I', 'had', 'to', 'buy', 'a', 'new', 'one', '.', 'Now', 'when', 'I', 'reins', '##tal', '##led', 'the', 'app', 'it', \"'\", 's', 'saying', 'that', 'I', 'need', 'to', 'start', 'collecting', 'again', 'and', 'to', 'log', 'in', 'I', 'need', 'a', 'premium', 'account', 'which', 'I', 'have', 'never', 'had', '.', 'How', 'can', 'I', 'get', 'my', 'points', 'back', '?', 'Thank', 'you', '.', '[SEP]']\n",
            "Ground truth label is neutral\n",
            "Prediction is positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_activations(input_ids, attention_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mof_JQC7OzGA",
        "outputId": "e659ee01-bd6e-4cdc-9f14-1525c6dd6ac0"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 2.0243027 , -0.77808666, -0.17660998, ...,  0.01387538,\n",
              "          0.15429512,  0.37072766],\n",
              "        [ 2.2487502 , -0.73420584,  0.06617729, ..., -0.03584908,\n",
              "          0.21698795,  0.26387444],\n",
              "        [ 1.9699428 , -0.8088339 , -0.5741832 , ...,  0.02192109,\n",
              "         -0.13866429,  0.37770966],\n",
              "        ...,\n",
              "        [ 2.5377512 , -0.4671873 ,  0.15997146, ..., -0.13483839,\n",
              "          0.3124979 ,  1.174147  ],\n",
              "        [ 2.0100698 , -0.48299772, -0.336403  , ..., -0.14898776,\n",
              "          0.04484099,  0.9281454 ],\n",
              "        [ 2.3049784 , -0.6505696 ,  0.08683315, ..., -0.28160125,\n",
              "          0.55691224,  0.22923389]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[:, pred_index].backward()"
      ],
      "metadata": {
        "id": "xIruQLpNKXq_"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients = model.get_activations_gradient()"
      ],
      "metadata": {
        "id": "LvqcoJ9Nc8BO"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx5zqE-sHDxB",
        "outputId": "e777e6ac-9a8a-45bf-d605-f493b8e400c5"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04],\n",
              "         [ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04],\n",
              "         [ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04],\n",
              "         ...,\n",
              "         [ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04],\n",
              "         [ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04],\n",
              "         [ 4.4222e-04,  4.4790e-04,  8.6981e-05,  ...,  1.5007e-04,\n",
              "           2.0501e-04, -4.5824e-04]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_gradients = torch.mean(gradients, dim=2)"
      ],
      "metadata": {
        "id": "c_itUA2aJVLh"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pooled_gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3zSOgTBJYY_",
        "outputId": "8ca4884a-dfb4-4d70-cb0d-35ff2d33e23a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06,\n",
              "         -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06, -7.3654e-06]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mNaI5nirJiGo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}